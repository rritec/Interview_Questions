{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "30xlUdtn7gTX"
   },
   "source": [
    "`1. What is the difference between Collinearity and correlation?`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jXsDvLHuE0zO"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Iog6sMJxdK8"
   },
   "outputs": [],
   "source": [
    "How to change threshold value of in logistic regression? (default is 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tt4eCYSgpUhh"
   },
   "source": [
    "`2. What to do if Multicollinearity exists?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1z-3EVtRpUho"
   },
   "outputs": [],
   "source": [
    "3. In Logistic regression how to interpret F1 Score, Support, Precesion, recall values? How do you conclude model is best or not best based on these parameters? Is there any threshold for  these parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DH2sCqsrnFW_"
   },
   "outputs": [],
   "source": [
    "4. How to read classification report when printed using print command? eg: print(classification_report(y_test,y_pred)). How to seperate precision, recall,support, f1-score etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dh0MVrSqnezT"
   },
   "outputs": [],
   "source": [
    "5. What is basic difference between GridSearchCV and RandomSearchCV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pIcp8niw9GKL"
   },
   "outputs": [],
   "source": [
    "6.what is auc and roc concept?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LJ7jBw9uohgP"
   },
   "outputs": [],
   "source": [
    "7. Explain parameters for GridSearchCV and RandomSearchCV for hypertunning of Logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pPopU5smq1pp"
   },
   "outputs": [],
   "source": [
    "8. While hypertunning of logistic regression what is use of c_space variable containing 15 log values between -5 to 8, code shown below  \n",
    "\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space}\n",
    "# Instantiate a logistic regression classifier: logreg\n",
    "logreg = LogisticRegression()\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "233oQQhq9D0P"
   },
   "outputs": [],
   "source": [
    "What is oversampling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4aBCAzhccOk"
   },
   "outputs": [],
   "source": [
    "What is bias and variance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dYj1Ni0KtnFM"
   },
   "outputs": [],
   "source": [
    "How AUC and Accuracy are different in Logistic regression? Does both indicate the same thing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "How to identify the number of principal components that needs to be used to perform dimensionality reduction? Number of principal components can be considered as a hyperparameter and can be provided multiple values with range function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "What needs to be done if reject_outliers didn't eliminate all the outliers? we have to know from the business if its genuine data, if not eliminate the data using custom conditions."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Machine Learning Interview questions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
